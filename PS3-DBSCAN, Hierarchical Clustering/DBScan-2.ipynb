{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import silhouette_score\n",
    "from collections import defaultdict\n",
    "import mnist_reader\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dbscan(data, eps, minpts=3,euclidean=True):\n",
    "    labels=[False for i in range(len(data))]\n",
    "    clusterIndex=1\n",
    "    \n",
    "    if(euclidean):\n",
    "        mat = euclidean_distances(data)\n",
    "    else:\n",
    "        mat = cosine_distances(data)\n",
    "        \n",
    "    for p in range(0,len(data)):                                          # Iterate over every point\n",
    "        if p%1000==0: print p\n",
    "        if not labels[p]:                                                 # Skip processed points\n",
    "            Neighbors = np.ix_(mat[p]<eps)[0].tolist()                    # Find initial neighbors\n",
    "            \n",
    "            if(len(Neighbors)<minpts):                                    # Non-core points are noise\n",
    "                labels[p]=-1\n",
    "            else:                                  \n",
    "                labels[p] = clusterIndex\n",
    "                i=0\n",
    "                while i < len(Neighbors):\n",
    "                    if labels[Neighbors[i]] == -1:\n",
    "                        labels[Neighbors[i]] = clusterIndex\n",
    "                    elif not labels[Neighbors[i]]:\n",
    "                        labels[Neighbors[i]] = clusterIndex\n",
    "                        ExtraNeighbors = np.ix_(mat[Neighbors[i]]<eps)[0].tolist()    # Expand neighborhood\n",
    "                        if(len(ExtraNeighbors)>=minpts):\n",
    "                            Neighbors = np.append(Neighbors,ExtraNeighbors)\n",
    "                    i=i+1\n",
    "                    \n",
    "                clusterIndex +=1                                                  # Start a new cluster\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performance_calculator(cluster,categories):\n",
    "    confusion_matrix=[]\n",
    "    for i in cluster:\n",
    "        countDict=defaultdict(int)\n",
    "        for j in cluster[i]:\n",
    "            countDict[j]+=1\n",
    "    \n",
    "        confusion_matrix.append([countDict[i] for i in range(categories)])\n",
    "    \n",
    "    \n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for i in confusion_matrix:\n",
    "        numerator+=max(i)\n",
    "        denominator+=sum(i)\n",
    "    \n",
    "    purity = float(numerator)/float(denominator)\n",
    "    \n",
    "    gini_indexes=[]\n",
    "    total=0\n",
    "    for i in confusion_matrix:\n",
    "        gi=1\n",
    "        for j in i:\n",
    "            if(sum(i)==0 and j==0):\n",
    "                gi=0\n",
    "            else:\n",
    "                gi-=((float(j)/float(sum(i)))**2)\n",
    "        gini_indexes.append(gi*sum(i))\n",
    "        total+=sum(i)\n",
    "        \n",
    "    gini = float(sum(gini_indexes))/float(total)\n",
    "    \n",
    "    return (purity,gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def form_clusters(predlabel,origlabel):\n",
    "    cluster=defaultdict(list)\n",
    "    for i in range(len(predlabel)):\n",
    "        cluster[predlabel[i]].append(origlabel[i])\n",
    "    return cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_clusters(cluster):\n",
    "    newCluster = defaultdict(list)\n",
    "    for i in cluster:\n",
    "        if(len(cluster[i])>0):\n",
    "            lab,_ = Counter(cluster[i]).most_common()[0]\n",
    "            newCluster[lab] = newCluster[lab] + cluster[i]\n",
    "    return newCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_dbscan(data,labels,eps,minpts=3,euclidean=True, sil = False):\n",
    "   \n",
    "    y_pred = dbscan(data,eps,minpts,euclidean)\n",
    "    \n",
    "    if(sil):\n",
    "        s = silhouette_score(data,y_pred)\n",
    "        cluster=form_clusters(y_pred,np.array(data))\n",
    "        print \"Silhouette:\",s\n",
    "        return cluster\n",
    "    else:\n",
    "        cluster=form_clusters(y_pred,labels)\n",
    "\n",
    "        noise = float(len(cluster[-1]))/float(len(data))\n",
    "        del cluster[-1]\n",
    "    \n",
    "        p,g = performance_calculator(cluster,20)\n",
    "        p,g = performance_calculator(merge_clusters(cluster),20)\n",
    "        print \"Noise: \",noise,\" Purity: \",p,\" Gini: \",g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ng = fetch_20newsgroups(subset='all')\n",
    "ng_X = ng.data\n",
    "ng_y = ng.target\n",
    "\n",
    "del(ng)\n",
    "count_vect = CountVectorizer(stop_words=\"english\",min_df=3,max_df=0.5)\n",
    "ng_X = count_vect.fit_transform(ng_X)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(use_idf=True)\n",
    "ng_X = tfidf_transformer.fit_transform(ng_X)\n",
    "\n",
    "ng_X = np.asarray(ng_X.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise:  0.315504616364  Purity:  0.384418604651  Gini:  0.674553341888\n"
     ]
    }
   ],
   "source": [
    "evaluate_dbscan(ng_X,ng_y,1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise:  0.117637695002  Purity:  0.105538517049  Gini:  0.90968598542\n"
     ]
    }
   ],
   "source": [
    "evaluate_dbscan(ng_X,ng_y,1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del (ng_X)\n",
    "del (ng_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FASHION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = mnist_reader.load_mnist('/Users/sasankauppu/DataMining/Assignment3/data/', kind='train')\n",
    "X_test, y_test = mnist_reader.load_mnist('/Users/sasankauppu/DataMining/Assignment3/data/', kind='t10k')\n",
    "\n",
    "fashion_X = np.concatenate((X_train,X_test))\n",
    "fashion_y = np.concatenate((y_train,y_test))\n",
    "\n",
    "del(X_train)\n",
    "del(X_test)\n",
    "del(y_train)\n",
    "del(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_data(data,label):\n",
    "    dfn=pd.DataFrame(data)\n",
    "    dfn[\"class\"]=label\n",
    "    dfarr=[]\n",
    "    for i in range(10):\n",
    "        dfarr.append(dfn[dfn[\"class\"]==i].sample(2000))\n",
    "\n",
    "    dfn = pd.concat(dfarr)\n",
    "    \n",
    "    y_actual = dfn[\"class\"]\n",
    "    del dfn[\"class\"]\n",
    "    \n",
    "    return dfn,y_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sf_X,sf_y = sample_data(fashion_X,fashion_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "Noise:  0.3479  Purity:  0.268747124674  Gini:  0.774375048463\n"
     ]
    }
   ],
   "source": [
    "evaluate_dbscan(sf_X,np.array(sf_y),0.06,3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "Noise:  0.2206  Purity:  0.129907621247  Gini:  0.88344157119\n"
     ]
    }
   ],
   "source": [
    "evaluate_dbscan(sf_X,np.array(sf_y),0.09,3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "Noise:  0.19165  Purity:  0.125997402115  Gini:  0.884499928277\n"
     ]
    }
   ],
   "source": [
    "evaluate_dbscan(sf_X,np.array(sf_y),0.1,3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del (sf_X)\n",
    "del (sf_y)\n",
    "del (fashion_X)\n",
    "del (fashion_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sasankauppu/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:6: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/sasankauppu/Desktop/Data Mining CS6220/DataMining/household_power_consumption.txt\",delimiter=';')\n",
    "\n",
    "del df[\"Date\"]\n",
    "del df[\"Time\"]\n",
    "\n",
    "df = df.drop(df.index[np.where(np.any(np.isnan(df.convert_objects(convert_numeric=True)),axis=1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.sample(int(0.01*len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = preprocessing.scale(df, with_mean=True, with_std=True, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "Silhouette: 0.155422431895\n"
     ]
    }
   ],
   "source": [
    "ct=evaluate_dbscan(df,[],0.6,3,True,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters: 60\n"
     ]
    }
   ],
   "source": [
    "print \"Clusters:\",len(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "Silhouette: 0.281242216427\n"
     ]
    }
   ],
   "source": [
    "ct=evaluate_dbscan(df,[],0.9,3,True,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters: 32\n"
     ]
    }
   ],
   "source": [
    "print \"Clusters:\",len(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
